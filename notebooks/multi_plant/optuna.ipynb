{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e12f9a-8b2b-4d16-b14d-1bf59b09c33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import subprocess; FOLDER_PATH = subprocess.Popen(['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE).communicate()[0].rstrip().decode('utf-8')\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sys, os; sys.path.append(os.path.dirname(f'{FOLDER_PATH}/utils')); sys.path.append(os.path.dirname(f'{FOLDER_PATH}/scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b55cebe3-9dc7-45ea-b3b9-4ba7189a73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from keras.backend import clear_session\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "from utils.tf_helpers import WindowGenerator, compile_and_fit, plot_plantwise_predictions\n",
    "from utils.base_helpers import read_data, split_data, scale_data, expand_data, plot_metrics\n",
    "from utils.graph_helpers import generate_adj_matrix, create_graph, LSTMGC, calculate_wmape_tf as wmape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7c8ccaa-9eac-492d-b9c9-00322354201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start and end dates:\t 2019-01-26 03:00:00 \t 2021-06-22 09:00:00\n",
      "Validation start and end dates:\t 2021-06-22 10:00:00 \t 2021-10-10 04:00:00\n",
      "Test start and end dates:\t 2021-10-10 05:00:00 \t 2022-01-27 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df, plants = read_data(generate_speed_angle=True, add_lagged=True, number_of_plants=8)\n",
    "train_df_, valid_df, test_df = split_data(df, train_ratio=0.8, valid_ratio=0.1)\n",
    "train_df, valid_df, test_df = expand_data(train_df_, valid_df, test_df)\n",
    "train_df, valid_df, test_df = scale_data(train_df, valid_df, test_df, plants, scaler=\"minmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e11e705a-ee3b-4314-88db-282554d66d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_STEPS = 24\n",
    "INPUT_WIDTH = 30\n",
    "\n",
    "window = WindowGenerator(\n",
    "    train_df=train_df, valid_df=valid_df, test_df=test_df, \n",
    "    columns=[col for col in df.columns if col != \"rt_plant_id\"],\n",
    "    input_width=INPUT_WIDTH, label_width=OUT_STEPS, shift=0, label_columns=[\"production\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f788dfb-168d-4238-a774-44ea1a84e616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 8, number of edges: 60\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix = generate_adj_matrix(train_df_, threshold=0.6)\n",
    "graph = create_graph(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a97af5e-186d-4f69-b3e4-635e0deab538",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "OUT_FEAT = 64\n",
    "lstm_units = 32\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_NODES = window.number_of_plants\n",
    "IN_FEAT = len(window.feature_column_indices)\n",
    "INPUT_SEQ_LEN = INPUT_WIDTH\n",
    "forecast_horizon = OUT_STEPS\n",
    "multi_horizon = True\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    clear_session()\n",
    "    \n",
    "    graph_aggregation_type = trial.suggest_categorical(\"graph_aggregation_type\", [\"mean\", \"sum\", \"max\"])\n",
    "    graph_combination_type = trial.suggest_categorical(\"graph_combination_type\", [\"concat\", \"add\"])\n",
    "    graph_activation = trial.suggest_categorical(\"graph_activation\", [\"relu\", \"linear\"])\n",
    "    lstm_activation = trial.suggest_categorical(\"lstm_activation\", [\"sigmoid\", \"relu\", \"tanh\"])\n",
    "    dense_activation = trial.suggest_categorical(\"dense_activation\", [\"relu\", \"sigmoid\"])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    loss = trial.suggest_categorical(\"loss\", [\"mse\", \"binary_crossentropy\"])\n",
    "    \n",
    "    graph_conv_params = {\"aggregation_type\": graph_aggregation_type, \"combination_type\": graph_combination_type, \"activation\": graph_activation,}\n",
    "    keras_params = {\"lstm_activation\": lstm_activation, \"dense_activation\": dense_activation}\n",
    "\n",
    "    st_gcn = LSTMGC(IN_FEAT, OUT_FEAT, lstm_units, INPUT_SEQ_LEN, \n",
    "        forecast_horizon, graph, graph_conv_params, keras_params)\n",
    "    inputs = layers.Input((INPUT_SEQ_LEN, graph.num_nodes, IN_FEAT))\n",
    "    outputs = st_gcn(inputs)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model, history = compile_and_fit(model, window, max_epochs=10, verbose=1, loss=loss,\n",
    "                                     optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate))\n",
    "    \n",
    "    score = model.evaluate(window.test, verbose=1)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b67ea34b-acbd-4972-aa7c-11ed32a1b441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmerts\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "2022-04-26 23:08:00.496640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 23:08:00.496657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mert/Desktop/thesis/notebooks/multi_plant/wandb/run-20220426_230754-1oijj6ja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/merts/optuna/runs/1oijj6ja\" target=\"_blank\">restful-puddle-1</a></strong> to <a href=\"https://wandb.ai/merts/optuna\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/merts/optuna/runs/1oijj6ja?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f18fd67deb0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "\n",
    "# wandb.init(project=\"optuna\", entity=\"merts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50788056-2234-492c-bd62-8d3602c98316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1oijj6ja) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-puddle-1</strong>: <a href=\"https://wandb.ai/merts/optuna/runs/1oijj6ja\" target=\"_blank\">https://wandb.ai/merts/optuna/runs/1oijj6ja</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220426_230754-1oijj6ja/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1oijj6ja). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 23:10:34.150751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-26 23:10:34.150767: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mert/Desktop/thesis/notebooks/multi_plant/wandb/run-20220426_231019-2dlvtbda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/merts/optuna/runs/2dlvtbda\" target=\"_blank\">warm-star-2</a></strong> to <a href=\"https://wandb.ai/merts/optuna\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "\n",
    "wandbc = WeightsAndBiasesCallback(metric_name=\"accuracy\", wandb_kwargs={\"project\": \"optuna\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e81730-4a1c-4516-a8e9-d36022a6b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:10:53,765]\u001b[0m A new study created in memory with name: no-name-ac06254b-d5e6-4f71-a2b9-6f4fd30dc0fd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1341 - wmape: 0.9125\n",
      "Epoch 1: val_wmape improved from inf to 0.68141, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 30ms/step - loss: 0.1341 - wmape: 0.9125 - val_loss: 0.1151 - val_wmape: 0.6814\n",
      "Epoch 2/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.1253 - wmape: 0.8818\n",
      "Epoch 2: val_wmape improved from 0.68141 to 0.66774, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1253 - wmape: 0.8817 - val_loss: 0.1106 - val_wmape: 0.6677\n",
      "Epoch 3/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.1192 - wmape: 0.8587\n",
      "Epoch 3: val_wmape improved from 0.66774 to 0.65373, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1192 - wmape: 0.8584 - val_loss: 0.1063 - val_wmape: 0.6537\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1144 - wmape: 0.8387\n",
      "Epoch 4: val_wmape improved from 0.65373 to 0.63955, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 28ms/step - loss: 0.1144 - wmape: 0.8387 - val_loss: 0.1018 - val_wmape: 0.6396\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.1101 - wmape: 0.8214\n",
      "Epoch 5: val_wmape improved from 0.63955 to 0.62602, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 28ms/step - loss: 0.1100 - wmape: 0.8213 - val_loss: 0.0977 - val_wmape: 0.6260\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1058 - wmape: 0.8035\n",
      "Epoch 6: val_wmape improved from 0.62602 to 0.61288, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1058 - wmape: 0.8035 - val_loss: 0.0939 - val_wmape: 0.6129\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.1016 - wmape: 0.7837\n",
      "Epoch 7: val_wmape improved from 0.61288 to 0.59934, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.1016 - wmape: 0.7833 - val_loss: 0.0901 - val_wmape: 0.5993\n",
      "Epoch 8/10\n",
      "327/329 [============================>.] - ETA: 0s - loss: 0.0972 - wmape: 0.7635\n",
      "Epoch 8: val_wmape improved from 0.59934 to 0.58586, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 28ms/step - loss: 0.0972 - wmape: 0.7633 - val_loss: 0.0864 - val_wmape: 0.5859\n",
      "Epoch 9/10\n",
      "327/329 [============================>.] - ETA: 0s - loss: 0.0927 - wmape: 0.7415\n",
      "Epoch 9: val_wmape improved from 0.58586 to 0.57224, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 27ms/step - loss: 0.0926 - wmape: 0.7415 - val_loss: 0.0828 - val_wmape: 0.5722\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0880 - wmape: 0.7180\n",
      "Epoch 10: val_wmape improved from 0.57224 to 0.55815, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 9s 28ms/step - loss: 0.0880 - wmape: 0.7180 - val_loss: 0.0791 - val_wmape: 0.5581\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1033 - wmape: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:12:26,751]\u001b[0m Trial 0 finished with value: 0.6545836925506592 and parameters: {'graph_aggregation_type': 'sum', 'graph_combination_type': 'add', 'graph_activation': 'linear', 'lstm_activation': 'sigmoid', 'dense_activation': 'sigmoid', 'learning_rate': 1.5855167918220696e-05, 'loss': 'mse'}. Best is trial 0 with value: 0.6545836925506592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.8827 - wmape: 0.5794\n",
      "Epoch 1: val_wmape improved from inf to 0.51243, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 33ms/step - loss: 0.8824 - wmape: 0.5791 - val_loss: 0.8528 - val_wmape: 0.5124\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.7023 - wmape: 0.4732\n",
      "Epoch 2: val_wmape improved from 0.51243 to 0.43157, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.7023 - wmape: 0.4732 - val_loss: 0.7841 - val_wmape: 0.4316\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6914 - wmape: 0.4461\n",
      "Epoch 3: val_wmape improved from 0.43157 to 0.40877, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6914 - wmape: 0.4461 - val_loss: 0.7964 - val_wmape: 0.4088\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6862 - wmape: 0.4335\n",
      "Epoch 4: val_wmape improved from 0.40877 to 0.39202, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6862 - wmape: 0.4335 - val_loss: 0.7627 - val_wmape: 0.3920\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6816 - wmape: 0.4223\n",
      "Epoch 5: val_wmape improved from 0.39202 to 0.37507, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6816 - wmape: 0.4223 - val_loss: 0.7572 - val_wmape: 0.3751\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6791 - wmape: 0.4152\n",
      "Epoch 6: val_wmape improved from 0.37507 to 0.35506, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6791 - wmape: 0.4152 - val_loss: 0.7458 - val_wmape: 0.3551\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6769 - wmape: 0.4104\n",
      "Epoch 7: val_wmape improved from 0.35506 to 0.34847, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6769 - wmape: 0.4104 - val_loss: 0.7449 - val_wmape: 0.3485\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6758 - wmape: 0.4067\n",
      "Epoch 8: val_wmape improved from 0.34847 to 0.34184, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 32ms/step - loss: 0.6758 - wmape: 0.4067 - val_loss: 0.7406 - val_wmape: 0.3418\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6739 - wmape: 0.4030\n",
      "Epoch 9: val_wmape improved from 0.34184 to 0.34015, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.6739 - wmape: 0.4029 - val_loss: 0.7409 - val_wmape: 0.3402\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6726 - wmape: 0.3993\n",
      "Epoch 10: val_wmape did not improve from 0.34015\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.6726 - wmape: 0.3992 - val_loss: 0.7595 - val_wmape: 0.3551\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7434 - wmape: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:14:16,722]\u001b[0m Trial 1 finished with value: 0.384509414434433 and parameters: {'graph_aggregation_type': 'sum', 'graph_combination_type': 'concat', 'graph_activation': 'linear', 'lstm_activation': 'sigmoid', 'dense_activation': 'relu', 'learning_rate': 0.0020698589074901455, 'loss': 'binary_crossentropy'}. Best is trial 1 with value: 0.384509414434433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.5773 - wmape: 0.6543\n",
      "Epoch 1: val_wmape improved from inf to 0.41860, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 34ms/step - loss: 0.5773 - wmape: 0.6543 - val_loss: 0.5503 - val_wmape: 0.4186\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4894 - wmape: 0.4517\n",
      "Epoch 2: val_wmape improved from 0.41860 to 0.36406, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 33ms/step - loss: 0.4894 - wmape: 0.4517 - val_loss: 0.5216 - val_wmape: 0.3641\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4717 - wmape: 0.4082\n",
      "Epoch 3: val_wmape improved from 0.36406 to 0.34372, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 13s 39ms/step - loss: 0.4717 - wmape: 0.4082 - val_loss: 0.5120 - val_wmape: 0.3437\n",
      "Epoch 4/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4635 - wmape: 0.3880\n",
      "Epoch 4: val_wmape improved from 0.34372 to 0.33486, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 0.4636 - wmape: 0.3882 - val_loss: 0.5120 - val_wmape: 0.3349\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4591 - wmape: 0.3775\n",
      "Epoch 5: val_wmape improved from 0.33486 to 0.32201, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 19s 56ms/step - loss: 0.4591 - wmape: 0.3775 - val_loss: 0.5075 - val_wmape: 0.3220\n",
      "Epoch 6/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4562 - wmape: 0.3705\n",
      "Epoch 6: val_wmape improved from 0.32201 to 0.31551, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 18s 56ms/step - loss: 0.4562 - wmape: 0.3705 - val_loss: 0.5011 - val_wmape: 0.3155\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4541 - wmape: 0.3653\n",
      "Epoch 7: val_wmape improved from 0.31551 to 0.31226, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 17s 52ms/step - loss: 0.4541 - wmape: 0.3653 - val_loss: 0.4986 - val_wmape: 0.3123\n",
      "Epoch 8/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4525 - wmape: 0.3613\n",
      "Epoch 8: val_wmape improved from 0.31226 to 0.30635, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.4524 - wmape: 0.3614 - val_loss: 0.4980 - val_wmape: 0.3063\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4509 - wmape: 0.3577\n",
      "Epoch 9: val_wmape did not improve from 0.30635\n",
      "329/329 [==============================] - 15s 44ms/step - loss: 0.4510 - wmape: 0.3577 - val_loss: 0.4985 - val_wmape: 0.3115\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4498 - wmape: 0.3551\n",
      "Epoch 10: val_wmape improved from 0.30635 to 0.29813, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 0.4498 - wmape: 0.3550 - val_loss: 0.4959 - val_wmape: 0.2981\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4850 - wmape: 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:16:46,726]\u001b[0m Trial 2 finished with value: 0.3385118842124939 and parameters: {'graph_aggregation_type': 'mean', 'graph_combination_type': 'concat', 'graph_activation': 'linear', 'lstm_activation': 'relu', 'dense_activation': 'sigmoid', 'learning_rate': 0.00015126983306713895, 'loss': 'binary_crossentropy'}. Best is trial 2 with value: 0.3385118842124939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.6214 - wmape: 0.6779\n",
      "Epoch 1: val_wmape improved from inf to 0.55675, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 13s 36ms/step - loss: 1.6214 - wmape: 0.6779 - val_loss: 1.9496 - val_wmape: 0.5567\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.5646 - wmape: 0.5773\n",
      "Epoch 2: val_wmape did not improve from 0.55675\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 1.5646 - wmape: 0.5773 - val_loss: 1.9493 - val_wmape: 0.5577\n",
      "Epoch 3/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 1.5578 - wmape: 0.5617\n",
      "Epoch 3: val_wmape improved from 0.55675 to 0.54053, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 1.5580 - wmape: 0.5616 - val_loss: 1.9401 - val_wmape: 0.5405\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.5547 - wmape: 0.5533\n",
      "Epoch 4: val_wmape improved from 0.54053 to 0.53520, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 1.5547 - wmape: 0.5533 - val_loss: 1.9374 - val_wmape: 0.5352\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 1.2867 - wmape: 0.5313\n",
      "Epoch 5: val_wmape improved from 0.53520 to 0.47659, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 1.2868 - wmape: 0.5311 - val_loss: 1.4158 - val_wmape: 0.4766\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.1247 - wmape: 0.5036\n",
      "Epoch 6: val_wmape improved from 0.47659 to 0.47215, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 1.1247 - wmape: 0.5036 - val_loss: 1.4144 - val_wmape: 0.4722\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.1201 - wmape: 0.4929\n",
      "Epoch 7: val_wmape did not improve from 0.47215\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 1.1201 - wmape: 0.4929 - val_loss: 1.4251 - val_wmape: 0.4943\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.1180 - wmape: 0.4880\n",
      "Epoch 8: val_wmape did not improve from 0.47215\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 1.1180 - wmape: 0.4880 - val_loss: 1.4132 - val_wmape: 0.4739\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 1.1166 - wmape: 0.4845\n",
      "Epoch 9: val_wmape improved from 0.47215 to 0.44968, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 1.1166 - wmape: 0.4845 - val_loss: 1.4034 - val_wmape: 0.4497\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 1.1152 - wmape: 0.4810\n",
      "Epoch 10: val_wmape did not improve from 0.44968\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 1.1152 - wmape: 0.4810 - val_loss: 1.4137 - val_wmape: 0.4642\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.2679 - wmape: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:18:45,988]\u001b[0m Trial 3 finished with value: 0.4573628008365631 and parameters: {'graph_aggregation_type': 'sum', 'graph_combination_type': 'add', 'graph_activation': 'linear', 'lstm_activation': 'sigmoid', 'dense_activation': 'relu', 'learning_rate': 0.002264491461655296, 'loss': 'binary_crossentropy'}. Best is trial 2 with value: 0.3385118842124939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.7007 - wmape: 0.9216\n",
      "Epoch 1: val_wmape improved from inf to 0.69001, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 15s 41ms/step - loss: 0.7006 - wmape: 0.9222 - val_loss: 0.6968 - val_wmape: 0.6900\n",
      "Epoch 2/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6737 - wmape: 0.8772\n",
      "Epoch 2: val_wmape improved from 0.69001 to 0.67467, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.6737 - wmape: 0.8770 - val_loss: 0.6873 - val_wmape: 0.6747\n",
      "Epoch 3/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6589 - wmape: 0.8475\n",
      "Epoch 3: val_wmape improved from 0.67467 to 0.66175, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.6588 - wmape: 0.8478 - val_loss: 0.6794 - val_wmape: 0.6617\n",
      "Epoch 4/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6470 - wmape: 0.8254\n",
      "Epoch 4: val_wmape improved from 0.66175 to 0.64558, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.6471 - wmape: 0.8250 - val_loss: 0.6688 - val_wmape: 0.6456\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6348 - wmape: 0.7999\n",
      "Epoch 5: val_wmape improved from 0.64558 to 0.62400, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.6347 - wmape: 0.8000 - val_loss: 0.6548 - val_wmape: 0.6240\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.6202 - wmape: 0.7712\n",
      "Epoch 6: val_wmape improved from 0.62400 to 0.59668, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.6202 - wmape: 0.7712 - val_loss: 0.6372 - val_wmape: 0.5967\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6035 - wmape: 0.7374\n",
      "Epoch 7: val_wmape improved from 0.59668 to 0.56532, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 42ms/step - loss: 0.6034 - wmape: 0.7372 - val_loss: 0.6182 - val_wmape: 0.5653\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.5856 - wmape: 0.6989\n",
      "Epoch 8: val_wmape improved from 0.56532 to 0.53516, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.5856 - wmape: 0.6989 - val_loss: 0.6010 - val_wmape: 0.5352\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5684 - wmape: 0.6605\n",
      "Epoch 9: val_wmape improved from 0.53516 to 0.50857, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.5684 - wmape: 0.6606 - val_loss: 0.5870 - val_wmape: 0.5086\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5526 - wmape: 0.6233\n",
      "Epoch 10: val_wmape improved from 0.50857 to 0.48703, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 43ms/step - loss: 0.5526 - wmape: 0.6232 - val_loss: 0.5765 - val_wmape: 0.4870\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5972 - wmape: 0.5818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:21:04,613]\u001b[0m Trial 4 finished with value: 0.5817617177963257 and parameters: {'graph_aggregation_type': 'max', 'graph_combination_type': 'concat', 'graph_activation': 'linear', 'lstm_activation': 'sigmoid', 'dense_activation': 'sigmoid', 'learning_rate': 2.982895312615913e-05, 'loss': 'binary_crossentropy'}. Best is trial 2 with value: 0.3385118842124939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0745 - wmape: 0.5331\n",
      "Epoch 1: val_wmape improved from inf to 0.34513, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 38ms/step - loss: 0.0744 - wmape: 0.5326 - val_loss: 0.0402 - val_wmape: 0.3451\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0386 - wmape: 0.3993\n",
      "Epoch 2: val_wmape improved from 0.34513 to 0.33724, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0386 - wmape: 0.3993 - val_loss: 0.0365 - val_wmape: 0.3372\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0350 - wmape: 0.3771\n",
      "Epoch 3: val_wmape improved from 0.33724 to 0.32594, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0350 - wmape: 0.3771 - val_loss: 0.0335 - val_wmape: 0.3259\n",
      "Epoch 4/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0327 - wmape: 0.3623\n",
      "Epoch 4: val_wmape improved from 0.32594 to 0.31104, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0327 - wmape: 0.3622 - val_loss: 0.0319 - val_wmape: 0.3110\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0312 - wmape: 0.3526\n",
      "Epoch 5: val_wmape improved from 0.31104 to 0.29798, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.0312 - wmape: 0.3526 - val_loss: 0.0321 - val_wmape: 0.2980\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0300 - wmape: 0.3441\n",
      "Epoch 6: val_wmape improved from 0.29798 to 0.28356, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0300 - wmape: 0.3441 - val_loss: 0.0289 - val_wmape: 0.2836\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0290 - wmape: 0.3377\n",
      "Epoch 7: val_wmape did not improve from 0.28356\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0290 - wmape: 0.3375 - val_loss: 0.0318 - val_wmape: 0.2915\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0284 - wmape: 0.3330\n",
      "Epoch 8: val_wmape improved from 0.28356 to 0.28291, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.0284 - wmape: 0.3330 - val_loss: 0.0287 - val_wmape: 0.2829\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0276 - wmape: 0.3282\n",
      "Epoch 9: val_wmape did not improve from 0.28291\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0276 - wmape: 0.3282 - val_loss: 0.0346 - val_wmape: 0.3091\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0271 - wmape: 0.3251\n",
      "Epoch 10: val_wmape did not improve from 0.28291\n",
      "329/329 [==============================] - 12s 38ms/step - loss: 0.0271 - wmape: 0.3251 - val_loss: 0.0302 - val_wmape: 0.2883\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0323 - wmape: 0.3096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:23:09,960]\u001b[0m Trial 5 finished with value: 0.30958807468414307 and parameters: {'graph_aggregation_type': 'mean', 'graph_combination_type': 'add', 'graph_activation': 'relu', 'lstm_activation': 'tanh', 'dense_activation': 'relu', 'learning_rate': 0.02054646775199676, 'loss': 'mse'}. Best is trial 5 with value: 0.30958807468414307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.5428 - wmape: 0.5920\n",
      "Epoch 1: val_wmape improved from inf to 0.37124, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 14s 37ms/step - loss: 0.5428 - wmape: 0.5920 - val_loss: 0.5266 - val_wmape: 0.3712\n",
      "Epoch 2/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4669 - wmape: 0.4025\n",
      "Epoch 2: val_wmape improved from 0.37124 to 0.33321, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4668 - wmape: 0.4025 - val_loss: 0.5088 - val_wmape: 0.3332\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4559 - wmape: 0.3722\n",
      "Epoch 3: val_wmape improved from 0.33321 to 0.31777, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.4559 - wmape: 0.3722 - val_loss: 0.5018 - val_wmape: 0.3178\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4512 - wmape: 0.3604\n",
      "Epoch 4: val_wmape did not improve from 0.31777\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4512 - wmape: 0.3604 - val_loss: 0.4988 - val_wmape: 0.3187\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4480 - wmape: 0.3513\n",
      "Epoch 5: val_wmape improved from 0.31777 to 0.30799, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.4480 - wmape: 0.3513 - val_loss: 0.4957 - val_wmape: 0.3080\n",
      "Epoch 6/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4455 - wmape: 0.3459\n",
      "Epoch 6: val_wmape improved from 0.30799 to 0.29537, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4455 - wmape: 0.3458 - val_loss: 0.4918 - val_wmape: 0.2954\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4437 - wmape: 0.3414\n",
      "Epoch 7: val_wmape improved from 0.29537 to 0.29292, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4438 - wmape: 0.3414 - val_loss: 0.4881 - val_wmape: 0.2929\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.4423 - wmape: 0.3375\n",
      "Epoch 8: val_wmape improved from 0.29292 to 0.29247, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4423 - wmape: 0.3375 - val_loss: 0.4882 - val_wmape: 0.2925\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4409 - wmape: 0.3340\n",
      "Epoch 9: val_wmape did not improve from 0.29247\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4409 - wmape: 0.3341 - val_loss: 0.4992 - val_wmape: 0.3097\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4397 - wmape: 0.3308\n",
      "Epoch 10: val_wmape did not improve from 0.29247\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.4397 - wmape: 0.3308 - val_loss: 0.4913 - val_wmape: 0.2960\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4685 - wmape: 0.3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:25:10,730]\u001b[0m Trial 6 finished with value: 0.3150860369205475 and parameters: {'graph_aggregation_type': 'mean', 'graph_combination_type': 'add', 'graph_activation': 'relu', 'lstm_activation': 'tanh', 'dense_activation': 'sigmoid', 'learning_rate': 0.00030924598310278926, 'loss': 'binary_crossentropy'}. Best is trial 5 with value: 0.30958807468414307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 1.8780 - wmape: 1.1921\n",
      "Epoch 1: val_wmape improved from inf to 0.76526, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 13s 36ms/step - loss: 1.8735 - wmape: 1.1908 - val_loss: 0.2001 - val_wmape: 0.7653\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1500 - wmape: 0.7386\n",
      "Epoch 2: val_wmape improved from 0.76526 to 0.66935, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.1500 - wmape: 0.7386 - val_loss: 0.1637 - val_wmape: 0.6693\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1257 - wmape: 0.6540\n",
      "Epoch 3: val_wmape improved from 0.66935 to 0.58712, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.1257 - wmape: 0.6540 - val_loss: 0.1348 - val_wmape: 0.5871\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.1185 - wmape: 0.6290\n",
      "Epoch 4: val_wmape did not improve from 0.58712\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.1185 - wmape: 0.6290 - val_loss: 0.1395 - val_wmape: 0.6056\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0774 - wmape: 0.5105\n",
      "Epoch 5: val_wmape improved from 0.58712 to 0.38701, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.0773 - wmape: 0.5101 - val_loss: 0.0568 - val_wmape: 0.3870\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0391 - wmape: 0.3964\n",
      "Epoch 6: val_wmape improved from 0.38701 to 0.35535, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.0391 - wmape: 0.3964 - val_loss: 0.0419 - val_wmape: 0.3554\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0357 - wmape: 0.3824\n",
      "Epoch 7: val_wmape improved from 0.35535 to 0.33888, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.0357 - wmape: 0.3824 - val_loss: 0.0400 - val_wmape: 0.3389\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0350 - wmape: 0.3782\n",
      "Epoch 8: val_wmape did not improve from 0.33888\n",
      "329/329 [==============================] - 12s 36ms/step - loss: 0.0350 - wmape: 0.3782 - val_loss: 0.0444 - val_wmape: 0.3620\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0344 - wmape: 0.3742\n",
      "Epoch 9: val_wmape did not improve from 0.33888\n",
      "329/329 [==============================] - 12s 37ms/step - loss: 0.0344 - wmape: 0.3744 - val_loss: 0.0455 - val_wmape: 0.3628\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.0338 - wmape: 0.3708\n",
      "Epoch 10: val_wmape did not improve from 0.33888\n",
      "329/329 [==============================] - 14s 41ms/step - loss: 0.0338 - wmape: 0.3708 - val_loss: 0.0425 - val_wmape: 0.3677\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0390 - wmape: 0.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-26 23:27:11,845]\u001b[0m Trial 7 finished with value: 0.34086930751800537 and parameters: {'graph_aggregation_type': 'sum', 'graph_combination_type': 'add', 'graph_activation': 'relu', 'lstm_activation': 'relu', 'dense_activation': 'relu', 'learning_rate': 0.008021477749997303, 'loss': 'mse'}. Best is trial 5 with value: 0.30958807468414307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0670 - wmape: 0.5070\n",
      "Epoch 1: val_wmape improved from inf to 0.39114, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 16s 44ms/step - loss: 0.0670 - wmape: 0.5070 - val_loss: 0.0568 - val_wmape: 0.3911\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0378 - wmape: 0.3899\n",
      "Epoch 2: val_wmape improved from 0.39114 to 0.33294, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 12s 35ms/step - loss: 0.0378 - wmape: 0.3899 - val_loss: 0.0390 - val_wmape: 0.3329\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - ETA: 0s - loss: 0.0326 - wmape: 0.3613\n",
      "Epoch 3: val_wmape improved from 0.33294 to 0.32081, saving model to /home/mert/Desktop/thesis/artifacts/checkpoint\n",
      "329/329 [==============================] - 11s 34ms/step - loss: 0.0326 - wmape: 0.3613 - val_loss: 0.0328 - val_wmape: 0.3208\n",
      "Epoch 4/10\n",
      " 19/329 [>.............................] - ETA: 11s - loss: 0.0312 - wmape: 0.3529"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, timeout=1200, callbacks=[wandbc])\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fe3c7-37c8-492c-9763-ebdc713c9c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
